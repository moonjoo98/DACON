{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec1cacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import ImageFilter, Image\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from functools import partial\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "from PIL import ImageFilter, Image\n",
    "from timm.data import auto_augment\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "_OP_CACHE = {}\n",
    "\n",
    "\n",
    "def _get_op(key, factory):\n",
    "    try:\n",
    "        op = _OP_CACHE[key]\n",
    "    except KeyError:\n",
    "        op = factory()\n",
    "        _OP_CACHE[key] = op\n",
    "    return op\n",
    "\n",
    "\n",
    "def _get_param(level, img, max_dim_factor, min_level=1):\n",
    "    max_level = max(min_level, max_dim_factor * max(img.size))\n",
    "    return round(min(level, max_level))\n",
    "\n",
    "\n",
    "def gaussian_blur(img, radius, **__):\n",
    "    radius = _get_param(radius, img, 0.1)\n",
    "    key = 'gaussian_blur_' + str(radius)\n",
    "    op = _get_op(key, lambda: ImageFilter.GaussianBlur(radius))\n",
    "    return img.filter(op)\n",
    "\n",
    "\n",
    "def motion_blur(img, k, **__):\n",
    "    k = _get_param(k, img, 5, 20) | 1  # bin to odd values\n",
    "    key = 'motion_blur_' + str(k)\n",
    "    op = _get_op(key, lambda: iaa.MotionBlur(k))\n",
    "    return Image.fromarray(op(image=np.asarray(img)))\n",
    "\n",
    "\n",
    "def gaussian_noise(img, scale, **_):\n",
    "    scale = _get_param(scale, img, 0.25) | 1  # bin to odd values\n",
    "    key = 'gaussian_noise_' + str(scale)\n",
    "    op = _get_op(key, lambda: iaa.AdditiveGaussianNoise(scale=scale))\n",
    "    return Image.fromarray(op(image=np.asarray(img)))\n",
    "\n",
    "\n",
    "def poisson_noise(img, lam, **_):\n",
    "    lam = _get_param(lam, img, 0.2) | 1  # bin to odd values\n",
    "    key = 'poisson_noise_' + str(lam)\n",
    "    op = _get_op(key, lambda: iaa.AdditivePoissonNoise(lam))\n",
    "    return Image.fromarray(op(image=np.asarray(img)))\n",
    "\n",
    "\n",
    "def _level_to_arg(level, _hparams, max):\n",
    "    level = max * level / auto_augment._LEVEL_DENOM\n",
    "    return level,\n",
    "\n",
    "\n",
    "_RAND_TRANSFORMS = auto_augment._RAND_INCREASING_TRANSFORMS.copy()\n",
    "_RAND_TRANSFORMS.remove('SharpnessIncreasing')  # remove, interferes with *blur ops\n",
    "_RAND_TRANSFORMS.extend([\n",
    "    'GaussianBlur',\n",
    "    'MotionBlur',\n",
    "    'GaussianNoise',\n",
    "    'PoissonNoise'\n",
    "])\n",
    "auto_augment.LEVEL_TO_ARG.update({\n",
    "    'GaussianBlur': partial(_level_to_arg, max=4),\n",
    "    'MotionBlur': partial(_level_to_arg, max=20),\n",
    "    'GaussianNoise': partial(_level_to_arg, max=0.1 * 255),\n",
    "    'PoissonNoise': partial(_level_to_arg, max=40)\n",
    "})\n",
    "auto_augment.NAME_TO_OP.update({\n",
    "    'GaussianBlur': gaussian_blur,\n",
    "    'MotionBlur': motion_blur,\n",
    "    'GaussianNoise': gaussian_noise,\n",
    "    'PoissonNoise': poisson_noise\n",
    "})\n",
    "\n",
    "\n",
    "def rand_augment_transform(magnitude=5, num_layers=3):\n",
    "    # These are tuned for magnitude=5, which means that effective magnitudes are half of these values.\n",
    "    hparams = {\n",
    "        'rotate_deg': 30,\n",
    "        'shear_x_pct': 0.9,\n",
    "        'shear_y_pct': 0.2,\n",
    "        'translate_x_pct': 0.10,\n",
    "        'translate_y_pct': 0.30\n",
    "    }\n",
    "    ra_ops = auto_augment.rand_augment_ops(magnitude, hparams, transforms=_RAND_TRANSFORMS)\n",
    "    # Supply weights to disable replacement in random selection (i.e. avoid applying the same op twice)\n",
    "    choice_weights = [1. / len(ra_ops) for _ in range(len(ra_ops))]\n",
    "    return auto_augment.RandAugment(ra_ops, num_layers, choice_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb13046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "        'rotate_deg': 45,\n",
    "        'shear_x_pct': 0.9,\n",
    "        'shear_y_pct': 0.2,\n",
    "        'translate_x_pct': 0.10,\n",
    "        'translate_y_pct': 0.30\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e74745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_ops = auto_augment.rand_augment_ops(5, hparams, transforms=_RAND_TRANSFORMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a61cad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_weights = [1. / len(ra_ops) for _ in range(len(ra_ops))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1bba682",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm=auto_augment.RandAugment(ra_ops, 3, choice_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce087fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./synthtiger/results/images/data/train.csv')\n",
    "df['len'] = df['label'].str.len()\n",
    "\n",
    "df['len'] = df['label'].str.len()\n",
    "train_v1 = df[df['len']==1]\n",
    "\n",
    "train_v1.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec7da152",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list=list(train_v1.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5634e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len이 1인 단어만 augmentation\n",
    "aug_df=pd.DataFrame()\n",
    "idx = 200000\n",
    "for i in tqdm(range(40000)):\n",
    "    select=random.randint(0,23702)\n",
    "    id_key=id_list[select]\n",
    "    imgFile1 = f'./synthtiger/results/images/data/train/{id_key}.png'\n",
    "\n",
    "    new_data = {\n",
    "        'id' : f\"aug_TRAIN_one_{idx:06d}\",\n",
    "        'img_path' : f\"./Cut_mix_one/TRAIN_one_{idx:06d}.png\",\n",
    "        'label' : train_v1['label'][select],\n",
    "        'len' : int(train_v1['len'][select])\n",
    "    }\n",
    "    aug_df=aug_df.append(new_data,ignore_index=True)\n",
    "    cut_mix_img=Image.open(imgFile1)\n",
    "    aug_img=tfm(cut_mix_img)\n",
    "    aug_img.save(f'./synthtiger/results/images/data/Cut_mix_one/TRAIN_one_{idx:06d}.png')\n",
    "    idx += 1\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len이 2인 단어만 augentation하기 위한 코드\n",
    "\n",
    "os.makedirs(\"./synthtiger/results/images/data/Cut_mix_two_new\", exist_ok=True)\n",
    "aug_df=pd.DataFrame()\n",
    "idx = 0\n",
    "for i in tqdm(range(30000)):\n",
    "    \n",
    "    select1, select2 = random.randint(0, 23702), random.randint(0, 23702)\n",
    "    id_key1=id_list[select1]\n",
    "    id_key2=id_list[select2]\n",
    "    imgFile1 = f'./synthtiger/results/images/data/train/{id_key1}.png'\n",
    "    imgFile2 = f'./synthtiger/results/images/data/train/{id_key2}.png'\n",
    "\n",
    "    img1 = cv2.imread(imgFile1, 1);\n",
    "    img2 = cv2.imread(imgFile2, 1);\n",
    "    \n",
    "    img1 = cv2.resize(img1,(100,125))\n",
    "    img2 = cv2.resize(img2,(100,125))\n",
    "    \n",
    "    addh = cv2.hconcat([img1, img2])\n",
    "    \n",
    "    new_data = {\n",
    "        'id' : f\"TRAIN_two{idx:06d}\",\n",
    "        'img_path' : f\"./Cut_mix_two_new/TRAIN_two{idx:06d}.png\",\n",
    "        'label' : train_v1['label'][select1] + train_v1['label'][select2],\n",
    "        'len' : train_v1['len'][select1] + train_v1['len'][select2]\n",
    "    }\n",
    "    \n",
    "    aug_df = aug_df.append(new_data, ignore_index=True)\n",
    "    cv2.imwrite(f\"./synthtiger/results/images/data/Cut_mix_two_new/TRAIN_two{idx:06d}.png\", addh)\n",
    "    new_data = {\n",
    "        'id' : f\"aug_TRAIN_two{idx:06d}\",\n",
    "        'img_path' : f\"./Cut_mix_two_new/aug_TRAIN_two{idx:06d}.png\",\n",
    "        'label' : train_v1['label'][select1] + train_v1['label'][select2],\n",
    "        'len' : train_v1['len'][select1] + train_v1['len'][select2]\n",
    "    }\n",
    "    aug_df=aug_df.append(new_data,ignore_index=True)\n",
    "    cut_mix_img=Image.open(f\"./synthtiger/results/images/data/Cut_mix_two_new/TRAIN_two{idx:06d}.png\")\n",
    "    aug_img=tfm(cut_mix_img)\n",
    "    aug_img.save(f'./synthtiger/results/images/data/Cut_mix_two_new/aug_TRAIN_two{idx:06d}.png')\n",
    "    idx += 1\n",
    "    print(idx)\n",
    "#     new_data = {\n",
    "#         'id' : f\"aug_TRAIN_one_{idx:06d}\",\n",
    "#         'img_path' : f\"./Cut_mix/TRAIN_one_{idx:06d}.png\",\n",
    "#         'label' : train_v1['label'][select],\n",
    "#         'len' : int(train_v1['len'][select])\n",
    "#     }\n",
    "#     aug_df=aug_df.append(new_data,ignore_index=True)\n",
    "#     cut_mix_img=Image.open(imgFile1)\n",
    "#     aug_img=tfm(cut_mix_img)\n",
    "#     aug_img.save(f'./synthtiger/results/images/data/Cut_mix/TRAIN_one_{idx:06d}.png')\n",
    "#     idx += 1\n",
    "#     print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c701f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>len_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>28631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   len  len_count\n",
       "0    2      28631\n",
       "1    1      23703\n",
       "2    3      13514\n",
       "3    4       9988\n",
       "4    5       1026\n",
       "5    6         26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_len_count = pd.DataFrame(df['len'].value_counts())\n",
    "df_len_count.reset_index(inplace=True)\n",
    "df_len_count.columns = ['len', 'len_count']\n",
    "\n",
    "display(df_len_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d118d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len2count = {k:v for k,v in zip(df_len_count['len'], df_len_count['len_count'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26768d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 train 데이터셋으로 이미지 cut-mix\n",
    "\n",
    "idx = 0\n",
    "for i in tqdm(range(300000)):\n",
    "    select1, select2 = random.randint(0, 76888), random.randint(0, 76888)\n",
    "    imgFile1 = f'./data/train/TRAIN_{select1:05d}.png'\n",
    "    imgFile2 = f'./data/train/TRAIN_{select2:05d}.png'\n",
    "    \n",
    "    if df['len'][select1] + df['len'][select2] > 6:\n",
    "        continue\n",
    "        \n",
    "    if len2count[df['len'][select1] + df['len'][select2]] > 200000:\n",
    "        continue\n",
    "    \n",
    "    # 이미지 읽기\n",
    "    img1 = cv2.imread(imgFile1, 1);\n",
    "    img2 = cv2.imread(imgFile2, 1);\n",
    "    \n",
    "    img1 = cv2.resize(img1,(100,125))\n",
    "    img2 = cv2.resize(img2,(100,125))\n",
    "    \n",
    "    addh = cv2.hconcat([img1, img2])\n",
    "    \n",
    "    new_data = {\n",
    "        'id' : f\"TRAIN_{idx:06d}\",\n",
    "        'img_path' : f\"./Cut_mix/TRAIN_{idx:06d}.png\",\n",
    "        'label' : df['label'][select1] + df['label'][select2],\n",
    "        'len' : df['len'][select1] + df['len'][select2]\n",
    "    }\n",
    "    \n",
    "    df = df.append(new_data, ignore_index=True)\n",
    "    cv2.imwrite(f\"./data/Cut_mix/TRAIN_{idx:06d}.png\", addh)\n",
    "    new_data = {\n",
    "        'id' : f\"aug_TRAIN_{idx:06d}\",\n",
    "        'img_path' : f\"./Cut_mix/aug_TRAIN_{idx:06d}.png\",\n",
    "        'label' : df['label'][select1] + df['label'][select2],\n",
    "        'len' : df['len'][select1] + df['len'][select2]\n",
    "    }\n",
    "    df=df.append(new_data,ignore_index=True)\n",
    "    cut_mix_img=Image.open(f\"./data/Cut_mix/TRAIN_{idx:06d}.png\")\n",
    "    aug_img=tfm(cut_mix_img)\n",
    "    aug_img.save(f'./data/Cut_mix/aug_TRAIN_{idx:06d}.png')\n",
    "    idx += 1\n",
    "    len2count[df['len'][select1] + df['len'][select2]] += 1\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f8c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.7 on Python 3.8 (CUDA 11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
